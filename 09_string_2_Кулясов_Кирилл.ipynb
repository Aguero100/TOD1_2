{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\кирилл\\appdata\\roaming\\python\\python39\\site-packages (0.9.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\кирилл\\appdata\\roaming\\python\\python39\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\кирилл\\appdata\\roaming\\python\\python39\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\кирилл\\appdata\\roaming\\python\\python39\\site-packages (from pymorphy2) (0.6.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: levenshtein in c:\\users\\кирилл\\appdata\\roaming\\python\\python39\\site-packages (0.21.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in c:\\users\\кирилл\\appdata\\roaming\\python\\python39\\site-packages (from levenshtein) (3.0.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stop-words in c:\\users\\кирилл\\appdata\\roaming\\python\\python39\\site-packages (2018.7.23)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2\n",
    "!pip install levenshtein\n",
    "!pip install stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in c:\\users\\кирилл\\appdata\\roaming\\python\\python39\\site-packages (23.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pymorphy2\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.metrics.distance import edit_distance\n",
    "import random\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial import distance\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['председательствовавший',\n",
       " 'стадвадцатипятирублевой',\n",
       " 'высокопревосходительство',\n",
       " 'высокопревосходительства',\n",
       " 'попреблагорассмотрительст',\n",
       " 'попреблагорассмотрительствующемуся',\n",
       " 'убегающих',\n",
       " 'уменьшившейся']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('litw-win.txt', 'r',encoding='windows-1251') as f:\n",
    "    words = [word.strip().split()[1] for word in f]\n",
    "words[-8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['с',\n",
       " 'величайшим',\n",
       " 'усилием',\n",
       " 'выбравшись',\n",
       " 'из',\n",
       " 'потока',\n",
       " 'убегающих',\n",
       " 'людей',\n",
       " 'кутузов',\n",
       " 'со',\n",
       " 'свитой',\n",
       " 'уменьшившейся',\n",
       " 'вдвое',\n",
       " 'поехал',\n",
       " 'на',\n",
       " 'звуки',\n",
       " 'выстрелов',\n",
       " 'русских',\n",
       " 'орудий']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'\n",
    "lst = []\n",
    "text5= word_tokenize(text)\n",
    "for i in range(len(text5)):\n",
    "    if text5[i] not in words:\n",
    "        text5[i] = min(words, key = lambda x: edit_distance(text5[i].lower(), x))\n",
    "text5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список слов:\n",
      "['Считайте', 'слова', 'из', 'файла', 'litw-win.txt', 'и', 'запишите', 'их', 'в', 'список', 'words', '.', 'В', 'заданном', 'предложении', 'исправьте', 'все', 'опечатки', ',', 'заменив', 'слова', 'с', 'опечатками', 'на', 'ближайшие', '(', 'в', 'смысле', 'расстояния', 'Левенштейна', ')', 'к', 'ним', 'слова', 'из', 'списка', 'words', '.', 'Считайте', ',', 'что', 'в', 'слове', 'есть', 'опечатка', ',', 'если', 'данное', 'слово', 'не', 'содержится', 'в', 'списке', 'words', '.']\n",
      "\n",
      "Стемминг:\n",
      "['счита', 'слов', 'из', 'файл', 'litw-win.txt', 'и', 'запиш', 'их', 'в', 'список', 'words', '.', 'в', 'зада', 'предложен', 'исправьт', 'все', 'опечатк', ',', 'замен', 'слов', 'с', 'опечатк', 'на', 'ближайш', '(', 'в', 'смысл', 'расстоян', 'левенштейн', ')', 'к', 'ним', 'слов', 'из', 'списк', 'words', '.', 'счита', ',', 'что', 'в', 'слов', 'ест', 'опечатк', ',', 'есл', 'дан', 'слов', 'не', 'содерж', 'в', 'списк', 'words', '.']\n",
      "\n",
      "Лемматизация:\n",
      "['Считайте', 'слова', 'из', 'файла', 'litw-win.txt', 'и', 'запишите', 'их', 'в', 'список', 'word', '.', 'В', 'заданном', 'предложении', 'исправьте', 'все', 'опечатки', ',', 'заменив', 'слова', 'с', 'опечатками', 'на', 'ближайшие', '(', 'в', 'смысле', 'расстояния', 'Левенштейна', ')', 'к', 'ним', 'слова', 'из', 'списка', 'word', '.', 'Считайте', ',', 'что', 'в', 'слове', 'есть', 'опечатка', ',', 'если', 'данное', 'слово', 'не', 'содержится', 'в', 'списке', 'word', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lst1= word_tokenize('''Считайте слова из файла litw-win.txt и запишите их в список words. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.''')\n",
    "lst2 = SnowballStemmer('russian')\n",
    "lst3 = WordNetLemmatizer()\n",
    "lst4 = [lst2.stem(i) for i in lst1]\n",
    "lst5 = [lst3.lemmatize(i) for i in lst1]\n",
    "print(f'Список слов:\\n{lst1}\\n')\n",
    "print(f'Стемминг:\\n{lst4}\\n')\n",
    "print(f'Лемматизация:\\n{lst5}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "        1, 3, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text7= ( 'Считайте слова из файла litw-win.txt и запишите их в список words.\\\n",
    "В заданном предложении исправьте все опечатки, заменив слова с опечатками на\\\n",
    "ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка,\\\n",
    "если данное слово не содержится в списке words')\n",
    "CountVectorizer().fit_transform(nltk.sent_tokenize(text7)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32868\n"
     ]
    }
   ],
   "source": [
    "dt = pd.read_csv('preprocessed_descriptions.csv')\n",
    "dt['preprocessed_descriptions'] = dt['preprocessed_descriptions'].astype(str)\n",
    "descriptions = ' '.join(list(dt['preprocessed_descriptions']))\n",
    "total_words = list(nltk.word_tokenize(descriptions.lower()))\n",
    "words = set(nltk.word_tokenize(descriptions.lower()))\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расстояние редактирования между 'rosettes' и 'quadrupled': 9\n",
      "Расстояние редактирования между 'httptinyurlcomlcvoq9' и 'battleaxe': 17\n",
      "Расстояние редактирования между 'forgets' и 'andrea': 6\n",
      "Расстояние редактирования между 'httpshoottocookcomrecipesbakingartisanbreadinfiveminutes' и 'swahali': 52\n",
      "Расстояние редактирования между 'line' и 'variant': 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Кирилл\\AppData\\Local\\Temp\\ipykernel_18136\\2671118893.py:3: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  word1, word2 = random.sample(words, 2)\n"
     ]
    }
   ],
   "source": [
    "from Levenshtein import distance\n",
    "for i in range(5):\n",
    "    word1, word2 = random.sample(words, 2)\n",
    "    # считаем расстояние редактирования между словами\n",
    "    edit_distance = distance(word1, word2)\n",
    "    # выводим результат\n",
    "    print(f\"Расстояние редактирования между '{word1}' и '{word2}': {edit_distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quadrupled', 'quadruple', 'quadrille']\n"
     ]
    }
   ],
   "source": [
    "def find_closest_words(word, words, k):\n",
    "    distances = [(distance(word, w), w) for w in words]\n",
    "    closest_words = sorted(distances)[:k]\n",
    "    return [w[1] for w in closest_words]\n",
    "word ='quadrupled'\n",
    "k=3\n",
    "closest_words = find_closest_words(word, words, k)\n",
    "print(closest_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rica</th>\n",
       "      <td>rica</td>\n",
       "      <td>rica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>folder</th>\n",
       "      <td>folder</td>\n",
       "      <td>folder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>musso</th>\n",
       "      <td>musso</td>\n",
       "      <td>musso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450000</th>\n",
       "      <td>450000</td>\n",
       "      <td>450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grazing</th>\n",
       "      <td>graze</td>\n",
       "      <td>grazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exaggeration</th>\n",
       "      <td>exagger</td>\n",
       "      <td>exaggeration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90100</th>\n",
       "      <td>90100</td>\n",
       "      <td>90100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139883the</th>\n",
       "      <td>139883the</td>\n",
       "      <td>139883the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enjoyablemost</th>\n",
       "      <td>enjoyablemost</td>\n",
       "      <td>enjoyablemost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                stemmed_word normalized_word\n",
       "word                                        \n",
       "rica                    rica            rica\n",
       "folder                folder          folder\n",
       "musso                  musso           musso\n",
       "450000                450000          450000\n",
       "grazing                graze         grazing\n",
       "...                      ...             ...\n",
       "exaggeration         exagger    exaggeration\n",
       "90100                  90100           90100\n",
       "139883the          139883the       139883the\n",
       "enjoyablemost  enjoyablemost   enjoyablemost\n",
       "100                      100             100\n",
       "\n",
       "[32868 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df = pd.DataFrame(words, columns = ['word'])\n",
    "df['stemmed_word'] = df.apply(lambda x: stemmer.stem(x['word']), axis = 1)\n",
    "df['normalized_word'] = df.apply(lambda x: lemmatizer.lemmatize(x['word']), axis = 1)\n",
    "df = df.set_index('word')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Кирилл\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля стоп-слов в общем количестве слов: 0.00%\n",
      "Топ-10 слов до удаления стоп-слов:\n",
      "[('recipe', 14871), ('make', 6326), ('time', 5137), ('use', 4620), ('great', 4430), ('like', 4167), ('easy', 4152), ('one', 3872), ('made', 3810), ('good', 3791)]\n",
      "Топ-10 слов после удаления стоп-слов:\n",
      "[('recipe', 14871), ('make', 6326), ('time', 5137), ('use', 4620), ('great', 4430), ('like', 4167), ('easy', 4152), ('one', 3872), ('made', 3810), ('good', 3791)]\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# функция для удаления стоп-слов из текста\n",
    "def remove_stopwords(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens_without_sw = [token for token in tokens if not token.lower() in stop_words]\n",
    "    return \" \".join(tokens_without_sw)\n",
    "\n",
    "dt['preprocessed_descriptions'] = dt['preprocessed_descriptions'].apply(remove_stopwords)\n",
    "total_words = dt['preprocessed_descriptions'].apply(lambda x: len(x.split())).sum()\n",
    "\n",
    "total_stop_words = dt['preprocessed_descriptions'].apply(lambda x: len([word for word in x.split() if word.lower() in stop_words])).sum()\n",
    "stop_words_proportion = total_stop_words / total_words\n",
    "\n",
    "print(f\"Доля стоп-слов в общем количестве слов: {stop_words_proportion:.2%}\")\n",
    "from collections import Counter\n",
    "\n",
    "# создание списка слов до удаления стоп-слов\n",
    "all_words_before = []\n",
    "for text in dt['preprocessed_descriptions']:\n",
    "    all_words_before += text.split()\n",
    "\n",
    "# подсчет частоты слов до удаления стоп-слов\n",
    "word_freq_before = Counter(all_words_before)\n",
    "\n",
    "# создание списка слов после удаления стоп-слов\n",
    "all_words_after = []\n",
    "for text in dt['preprocessed_descriptions']:\n",
    "    all_words_after += remove_stopwords(text).split()\n",
    "\n",
    "# подсчет частоты слов после удаления стоп-слов\n",
    "word_freq_after = Counter(all_words_after)\n",
    "\n",
    "# вывод топ-10 самых часто употребляемых слов до и после удаления стоп-слов\n",
    "print(\"Топ-10 слов до удаления стоп-слов:\")\n",
    "print(word_freq_before.most_common(10))\n",
    "\n",
    "print(\"Топ-10 слов после удаления стоп-слов:\")\n",
    "print(word_freq_after.most_common(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рецепт 1\n",
      "\n",
      "[[0.         0.         0.23375059 0.         0.         0.\n",
      "  0.         0.         0.1885885  0.         0.         0.\n",
      "  0.         0.23375059 0.23375059 0.         0.23375059 0.\n",
      "  0.         0.23375059 0.23375059 0.23375059 0.         0.\n",
      "  0.         0.         0.         0.         0.23375059 0.\n",
      "  0.         0.         0.23375059 0.         0.23375059 0.23375059\n",
      "  0.1885885  0.         0.         0.         0.         0.23375059\n",
      "  0.         0.         0.         0.         0.23375059 0.\n",
      "  0.23375059 0.         0.23375059 0.         0.         0.23375059\n",
      "  0.23375059 0.         0.        ]] \n",
      "\n",
      "Рецепт 2\n",
      "\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.62791376 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.77828292\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]] \n",
      "\n",
      "Рецепт 3\n",
      "\n",
      "[[0.19245009 0.         0.         0.19245009 0.19245009 0.19245009\n",
      "  0.19245009 0.         0.         0.         0.19245009 0.\n",
      "  0.19245009 0.         0.         0.19245009 0.         0.\n",
      "  0.19245009 0.         0.         0.         0.19245009 0.\n",
      "  0.19245009 0.         0.         0.19245009 0.         0.\n",
      "  0.19245009 0.19245009 0.         0.38490018 0.         0.\n",
      "  0.         0.         0.19245009 0.19245009 0.19245009 0.\n",
      "  0.         0.         0.19245009 0.19245009 0.         0.\n",
      "  0.         0.19245009 0.         0.19245009 0.19245009 0.\n",
      "  0.         0.19245009 0.        ]] \n",
      "\n",
      "Рецепт 4\n",
      "\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.70710678 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.70710678]] \n",
      "\n",
      "Рецепт 5\n",
      "\n",
      "[[0.         0.29296785 0.         0.         0.         0.\n",
      "  0.         0.29296785 0.         0.29296785 0.         0.29296785\n",
      "  0.         0.         0.         0.         0.         0.29296785\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.29296785 0.29296785 0.         0.         0.29296785\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23636462 0.29296785 0.         0.         0.         0.\n",
      "  0.         0.29296785 0.         0.         0.         0.29296785\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt2 = dt.sample(n=5)\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(dt2['preprocessed_descriptions'])\n",
    "for i, vector in enumerate(vectors):\n",
    "    print(f\"Рецепт {i+1}\\n\")\n",
    "    print(vector.toarray(), '\\n')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>pumpkin  rocket and pomegranate salad</th>\n",
       "      <th>cheese spread dice</th>\n",
       "      <th>tropical fruit medley soup or dessert</th>\n",
       "      <th>easy oven rice</th>\n",
       "      <th>classic caesar salad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pumpkin  rocket and pomegranate salad</th>\n",
       "      <td>1</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cheese spread dice</th>\n",
       "      <td>0.118417</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tropical fruit medley soup or dessert</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy oven rice</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classic caesar salad</th>\n",
       "      <td>0.044576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name                                  pumpkin  rocket and pomegranate salad  \\\n",
       "                                                                              \n",
       "pumpkin  rocket and pomegranate salad                                     1   \n",
       "cheese spread dice                                                 0.118417   \n",
       "tropical fruit medley soup or dessert                                   0.0   \n",
       "easy oven rice                                                          0.0   \n",
       "classic caesar salad                                               0.044576   \n",
       "\n",
       "name                                  cheese spread dice  \\\n",
       "                                                           \n",
       "pumpkin  rocket and pomegranate salad           0.118417   \n",
       "cheese spread dice                                     1   \n",
       "tropical fruit medley soup or dessert                0.0   \n",
       "easy oven rice                                       0.0   \n",
       "classic caesar salad                                 0.0   \n",
       "\n",
       "name                                  tropical fruit medley soup or dessert  \\\n",
       "                                                                              \n",
       "pumpkin  rocket and pomegranate salad                                   0.0   \n",
       "cheese spread dice                                                      0.0   \n",
       "tropical fruit medley soup or dessert                                     1   \n",
       "easy oven rice                                                          0.0   \n",
       "classic caesar salad                                                    0.0   \n",
       "\n",
       "name                                  easy oven rice classic caesar salad  \n",
       "                                                                           \n",
       "pumpkin  rocket and pomegranate salad            0.0             0.044576  \n",
       "cheese spread dice                               0.0                  0.0  \n",
       "tropical fruit medley soup or dessert            0.0                  0.0  \n",
       "easy oven rice                                     1                  0.0  \n",
       "classic caesar salad                             0.0                    1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "dt2['preprocessed_descriptions'] = dt2['preprocessed_descriptions'].astype(str)\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(dt2['preprocessed_descriptions']).toarray()\n",
    "dt44 = pd.DataFrame(index = dt2['name'], columns = dt2['name'])\n",
    "for i, r1 in enumerate(dt2['name']):\n",
    "    for j, r2 in enumerate(dt2['name']):\n",
    "        dt44.at[r1, r2] = 1 - cosine(vectors[i], vectors[j])\n",
    "dt44 = dt44.reset_index().rename(columns={'name': ' '})\n",
    "dt44 = dt44.set_index(' ')\n",
    "dt44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>pumpkin  rocket and pomegranate salad</th>\n",
       "      <th>cheese spread dice</th>\n",
       "      <th>tropical fruit medley soup or dessert</th>\n",
       "      <th>easy oven rice</th>\n",
       "      <th>classic caesar salad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pumpkin  rocket and pomegranate salad</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cheese spread dice</th>\n",
       "      <td>0.118417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tropical fruit medley soup or dessert</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy oven rice</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classic caesar salad</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name                                  pumpkin  rocket and pomegranate salad  \\\n",
       "                                                                              \n",
       "pumpkin  rocket and pomegranate salad                                   NaN   \n",
       "cheese spread dice                                                 0.118417   \n",
       "tropical fruit medley soup or dessert                                   NaN   \n",
       "easy oven rice                                                          NaN   \n",
       "classic caesar salad                                                    NaN   \n",
       "\n",
       "name                                  cheese spread dice  \\\n",
       "                                                           \n",
       "pumpkin  rocket and pomegranate salad           0.118417   \n",
       "cheese spread dice                                   NaN   \n",
       "tropical fruit medley soup or dessert                NaN   \n",
       "easy oven rice                                       NaN   \n",
       "classic caesar salad                                 NaN   \n",
       "\n",
       "name                                  tropical fruit medley soup or dessert  \\\n",
       "                                                                              \n",
       "pumpkin  rocket and pomegranate salad                                   0.0   \n",
       "cheese spread dice                                                      0.0   \n",
       "tropical fruit medley soup or dessert                                   NaN   \n",
       "easy oven rice                                                          0.0   \n",
       "classic caesar salad                                                    0.0   \n",
       "\n",
       "name                                  easy oven rice classic caesar salad  \n",
       "                                                                           \n",
       "pumpkin  rocket and pomegranate salad            0.0             0.044576  \n",
       "cheese spread dice                               0.0                  NaN  \n",
       "tropical fruit medley soup or dessert            0.0                  NaN  \n",
       "easy oven rice                                   NaN                  NaN  \n",
       "classic caesar salad                             0.0                  NaN  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recept = dt44[dt44 != 1].max().values # список значений наибоолее похожих рецептов\n",
    "dt44[dt44 == recept] #датафрейм,c наиболее похожими рецептами\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
